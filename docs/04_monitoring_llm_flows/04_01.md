---
title: '1. Monitoring your LLMs flows'
layout: default
nav_order: 1
parent: 'Exercise 04: Monitoring LLMs'
---

# Task 01 - Monitoring your LLM flows

## Description

In this task, you will create and configure a monitoring solutions for the flows created in the previous exercises.

## Success Criteria

* Verify the monitoring through flow testing

## Solution

<details markdown="block">
<summary>Expand this section to view the solution</summary>

##### 1) Monitoring your LLMs flow

Modify the output node of the workflow to incorporate the required information for computing the metrics that need monitoring, as outlined below.

Be sure to activate monitoring by selecting the "Enable" button within the Model Monitoring section when deploying the workflow. Then test the flows and see how the monitoring reacts and what information you can gather from that monitoring.

1. Sign in to Azure AI Studio.

2. Go to your Azure Studio Project.

3. From the left navigation bar, got to Tools > Prompt Flow.

4. Select the prompt flow that you created previously.

5. Confirm that your flow runs successfully and that the required inputs and outputs are configured for the metrics you want to assess. Supplying the minimum required parameters (question/inputs and answer/outputs) provides only two metrics: coherence and fluency. This example uses, question (Question) and chat_history (Context) as the flow inputs, and answer (Answer) as the flow output.

6. Select **Deploy** to begin deploying your flow.

  Insert Image here

7. In the deployment window, ensure that **Inferencing data collection** is enabled, which will seamlessly collect your application's inference data to Blob Storage. This data collection is required for monitoring.

   Insert Image here

8. Proceed through the steps in the deployment window to complete the **Advanced settings**.

9. On the "Review" page, review the deployment configuration and select **Create** to deploy your flow.

    Insert Image here

10. Select the **Test** tab on the deployment page, and test your deployment to ensure that it's working properly.

    Insert Image here

</details>
