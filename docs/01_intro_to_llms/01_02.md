---
title: '2. Work with an Open Source LLM Model'
layout: default
nav_order: 3
parent: 'Exercise 01: Introduction to LLMs and Azure AI Services'
---

# Task 02 - Work with an Open Source LLM Model

## Description

In this task, you will create and configure and Azure AI Studio Build deployment with an open source LLM

## Success Criteria

* Create a deployment with Llama-2-13b-chat and validated it.

## Solution

<details markdown="block">
<summary>Expand this section to view the solution</summary>

##### 2) Work with an Open Source LLM Model

Now let's test an open source Llama2 model from Meta.

1. For this, go to the **Deployments** section in the **Build** tab and click on **Create deployment**.

![LLMOps Workshop](images/labgrab17.png)

2. Select the model **Llama-2-13b-chat** and click on **confirm**.

![LLMOps Workshop](images/labgrab18.png)

3. Select the deployment option **Managed Compute without Azure AI Content Safety**.

![LLMOps Workshop](images/labgrab19.png)

4. Check the box that shows **I want to use shared quota and I acknowledge that this endpoint will be deleted in 168 hours.**.

5. Select the **Standard_NC24s_v3** compute for inference with the selected model, for this workshop one instance is enough.

6. If you do not have enough quota you can access the AzureML Quota option in the Managed tab to request an increase in quota for the selected resource.

7. Click the **Deploy** button.

![LLMOps Workshop](images/labgrab20.png)

8. The creation of the deployment will take a few minutes, the time varies, but generally between 10 and 20 minutes. ( If you notice your Traffic allocation is 0% select **Update traffic** and set it to 100%, if you get an error try again.)

![LLMOps Workshop](images/labgrab21.png)

Done! Let's test this model by selecting the **Test** option on the deployment page.

9. Select the gear icon on the top right of the chat and adjust the ```max_next_tokens``` parameter to 1000 so we can test the same example we used with the gpt-4 model. **Click Accept**

![LLMOps Workshop](images/labgrab22.png)

10. Now just copy the text below into the "Start typing here text box" and then send to observe the response generated by the Llama2 model.

```
{
  "input_data": {
    "input_string": [
      {
        "role": "system",
        "content": "You're an AI assistant that helps telco company to extract valuable information from their conversations by creating JSON documents for each conversation transcription you receive. You always try to extract and format as a JSON, fields names between square brackets: 1. Customer Name [name] 2. Customer Contact Phone [phone] 3. Main Topic of the Conversation [topic] 4. Customer Sentiment (Neutral, Positive, Negative)[sentiment] 5. How the Agent Handled the Conversation [agent_behavior] 6. What was the FINAL Outcome of the Conversation [outcome] 7. A really brief Summary of the Conversation [summary] Only extract information that you're sure. If you're unsure, write 'Unknown/Not Found' in the JSON file. Your answers outputs contains only the json document."
      },
      {
        "role": "user",
        "content": "Agent: Hello, welcome to Telco's customer service. My name is Juan, how can I assist you? Client: Hello, Juan. I'm calling because I'm having issues with my mobile data plan. It's very slow and I can't browse the internet or use my apps. Agent: I'm very sorry for the inconvenience, sir. Could you please tell me your phone number and your full name? Client: Yes, sure. My number is 011-4567-8910 and my name is Martín Pérez. Agent: Thank you, Mr. Pérez. I'm going to check your plan and your data usage. One moment, please. Client: Okay, thank you. Agent: Mr. Pérez, I've reviewed your plan and I see that you have contracted the basic plan of 2 GB of data per month. Is that correct? Client: Yes, that's correct. Agent: Well, I inform you that you have consumed 90% of your data limit and you only have 200 MB available until the end of the month. That's why your browsing speed has been reduced. Client: What? How is that possible? I barely use the internet on my cell phone. I only check my email and my social networks from time to time. I don't watch videos or download large files. Agent: I understand, Mr. Pérez. But keep in mind that some applications consume data in the background, without you realizing it. For example, automatic updates, backups, GPS, etc. Client: Well, but they didn't explain that to me when I contracted the plan. They told me that with 2 GB I would have enough for the whole month. I feel cheated. Agent: I apologize, Mr. Pérez. It was not our intention to deceive you. I offer you a solution: if you want, you can change your plan to a higher one, with more GB of data and higher speed. This way you can enjoy a better browsing experience. Client: And how much would that cost me? Agent: We have a special offer for you. For only 10 pesos more per month, you can access the premium plan of 5 GB of data and 4G speed. Are you interested? Client: Mmm, I don't know. Isn't there another option? Can't you give me more speed without charging me more? Agent: I'm sorry, Mr. Pérez. That's the only option we have available. If you don't change your plan, you'll have to wait until next month to recover your normal speed. Or you can buy an additional data package, but it would be more expensive than changing plans. Client: Well, let me think about it. Can I call later to confirm? Agent: Of course, Mr. Pérez. You can call whenever you want. The number is the same one you dialed now. Is there anything else I can help you with? Client: No, that's all. Thank you for your attention. Agent: Thank you, Mr. Pérez. Have a good day. Goodbye."
      }
    ],
    "parameters": {
      "temperature": 0.8,
      "top_p": 0.8,
      "do_sample": true,
      "max_new_tokens": 1000
    }
  }
}
```

You will see a result generated by the model similar to the one shown in the image below.

![LLMOps Workshop](images/labgrab23.png)

</details>
